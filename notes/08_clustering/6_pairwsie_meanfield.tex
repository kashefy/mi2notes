\subsection{The mean-field approximation for pairwise clustering}

\begin{frame}[t] 
\slidesonly{\frametitle{\subsecname}}

\svspace{-3mm}

\begin{block}{assignment noise $\rightarrow$ Gibbs distribution}
\begin{equation}
	P_{ \big( \big\{ m_q^{(\alpha)} \big\} \big) }
	= \frac{1}{Z_p} \exp \Big\{ -\beta 
	\overbrace{
		E_{\big[ \big\{ m_q^{(\alpha)} \big\} \big]}
		}^{= \, E_p}
		\Big\}
\end{equation}
where
\begin{equation}
	Z_p = \sum\limits_{\mathscr{M}} \exp \Big\{ -\beta
		E_p
		\Big\}
\end{equation}
\end{block}
\notesonly{
This is approximated by the mean-fields:
}
\begin{block}{factorizing distribution}
\begin{equation}
	Q_{ \big[ \big\{ m_q^{(\alpha)} \big\} \big] }
	= \frac{1}{Z_Q} \exp \Big\{ -\beta \sum\limits_{q, \gamma}
		m_q^{(\gamma)} \underbrace{ e_q^{(\gamma)} }_{
			\text{{\tiny mean-fields}} } \Big\}
\end{equation}
where:
\begin{equation}
	Z_Q = \sum\limits_{\mathscr{M}} \exp \Big\{ -\beta \sum\limits_{q, 
		\gamma} m_q^{(\gamma)} e_q^{(\gamma)} \Big\}
\end{equation}
\end{block}
\end{frame}

\subsubsection{Calculation of the moments}

\begin{frame}\frametitle{Recap calculation of the moments (general mean-field case)}
The factorization of the distribution $Q$ simplifies the calculation of the moments. 
This is based on the individual state variables being \emph{uncorrelated}.

\begin{equation}\label{eq:factorizingMoments}
	\Big< f_{(\vec{s}/s_l)} g_{(s_l)} \Big>_Q
	 = \frac{1}{Z_Q} \sum\limits_{\vec{s}} f_{(\vec{s}/s_l)}
		g_{(s_l)} \exp \Big( -\beta \sum\limits_k e_k s_k \Big)
\end{equation}

\end{frame}

\mode<article>{

\begin{frame}
\slidesonly{
\frametitle{Factorizing moments (general mean-field case)}
\vspace{-0.5cm}
\begin{equation}\label{eq:factorizingMoments}
	\Big< f_{(\vec{s}/s_l)} g_{(s_l)} \Big>_Q
	 = \frac{1}{Z_Q} \sum\limits_{\vec{s}} f_{(\vec{s}/s_l)}
		g_{(s_l)} \exp \Big( -\beta \sum\limits_k e_k s_k \Big)
\end{equation}
}
\begin{eqnarray*}
	& = & \frac{1}{Z_Q} \bigg[ \sum\limits_{\vec{s}/s_l} f_{(\vec{s}/s_l)}
		\exp \Big( -\beta \sum\limits_{k \neq l} e_k s_k \Big) \bigg]
		\bigg[ \sum\limits_{s_l} g_{(s_l)} \exp \Big( -\beta e_l
			s_l \Big) \bigg] \\\\
	& = & \frac{1}{Z_Q} \bigg[ \sum\limits_{\vec{s}/s_l} f_{(\vec{s}/s_l)}
		\exp \Big( -\beta \sum\limits_{k \neq l} e_k s_k \Big) \bigg]\\
		&&\qquad\qquad
  \frac{\color{blue}{\sum\limits_{s_l} \exp(-\beta e_l s_l)}}{\sum\limits_{s_l}
		\exp(-\beta e_l s_l)}
		\bigg[ {\color{blue}\sum\limits_{s_l}} g_{(s_l)} \color{blue}{\exp \Big( -\beta e_l
			s_l \Big)} \bigg] \\\\
	& = &\big< f_{(\vec{s}/s_l)} \big>_Q \frac{\sum\limits_{s_l}
		g_{(s_l)} \exp(-\beta e_l s_l)}{\sum\limits_{s_l}
		\exp(-\beta e_l s_l)} = 
	\underbrace{ \big< f_{(\vec{s}/s_l)} \big>_Q \cdot \big<g_{(s_l)} 
		\big>_Q }_{ 	\substack{ \text{factorization of moments} \\
				\rightarrow \text{uncorrelated variables}} }
\end{eqnarray*}

\end{frame}

\begin{frame}
\notesonly{Some nomenclature before we demonstrate the same factorization for the assignment variables in pairwise clustering.}
\slidesonly{ Nomenclature }($\otimes$ $\rightarrow$ \emph{set-product, Cartesian product})\\
 
 \begin{tabular}{r l p{9cm}}
$\big\{ \vec{m}^{(\alpha)} \big\}$: & & set of all $M$-dimensional binary vectors $\big( m_1^{(\alpha)}, m_2^{(\alpha)}, \ldots, 
  m_M^{(\alpha)} \big)^\top$ which fulfill the normalization condition (exactly one element equals 1). \\\\
$\mathscr{M}$: & & $\big\{ \vec{m}^{(1)} \big\} \otimes \big\{ \vec{m}^{(2)} \big\} \otimes \ldots \otimes \big\{ \vec{m}^{(p)} \big\}$\\
& & set-product (Cartesian product) between all possible binary assignment variables i.e.\ all possible valid assignments for the full dataset\\\\
$\mathscr{M}_{\gamma}$:& &  $\big\{ \vec{m}^{(1)} \big\} \otimes \ldots \otimes \big\{ \vec{m}^{(\gamma - 1)} \big\} \otimes
  \big\{ \vec{m}^{(\gamma + 1)} \big\} \otimes \ldots \otimes
  \big\{ \vec{m}^{(p)} \big\}$\\
& &\  set of all possible assignments for all data points  \\& & \hspace{0.03cm} except $\gamma$
\end{tabular}

\end{frame}

}

\begin{frame}
\slidesonly{\frametitle{Calculation of moments for the assignment variables}}
\begin{equation}
		\begin{array}{lll}
	\big< m_q^{(\gamma)} \big>_Q
	& = \frac{1}{Z_Q} \sum\limits_{\mathscr{M}} m_q^{(\gamma)}
		\exp \Big\{ -\beta \sum\limits_{r, \delta} 
		m_{r}^{(\delta)} e_{r}^{(\delta)} \Big\}
	\end{array}
\end{equation}

\slidesonly{
\begin{itemize}
\itr The factorization of $Q$ simplifies the calculation of the moments.
\end{itemize}

Here,\\
$\mathscr{M}$ is the set-product (Cartesian product) between \textbf{all possible} binary assignment variables i.e.\ all possible valid assignments for the full dataset.
}

\end{frame}

\mode<article>{

\begin{frame}
\slidesonly{\frametitle{Calculation of moments (derivation)}
The factorization in \eqref{eq:factorizingMoments}) regarding valid assignments $\big\{ \vec{m}^{(\gamma)} \big\}$ for observation $\gamma$ and the rest of the variables excluding $\gamma$ (i.e. $\mathscr{M}_{\gamma}$) is valid for any functions $f,g$:
}
\begin{align}
	\sum\limits_{\mathscr{M}} \Big[ f_{ \big( \big\{ m_p^{(\delta)} 
		\big| \delta \neq \gamma \big\} \big) }
		\cdot \, g_{ \big( \big\{ m_p^{(\delta)} \big| \delta = \gamma 
			\big\} \big) }
		\Big]\\
		\qquad
	\qquad\qquad= \Big[ \sum\limits_{\mathscr{M}_{\gamma}} f_{ \big( \big\{ 
		m_p^{(\delta)} \big| \delta \neq \gamma \big\} \big) }
		\Big] \cdot \Big[ \sum\limits_{\big\{ \vec{m}^{(\gamma)} 
			\big\} } g_{ \big( \big\{ m_p^{(\delta)} \big| \delta = 
			\gamma \big\} \big) } \Big]
\end{align}
this gives
%% this formula has been seriously confusing / wrong (indices?) so double check
\begin{equation}
	\begin{array}{ll}
	\big< m_q^{(\gamma)} \big>_Q
	& = \frac{ \Bigg[ \sum\limits_{\mathscr{M}_{\gamma}} \exp \Big\{ -\beta
		\sum\limits_{r, \delta \neq \gamma} m_{r}^{(\delta)}
		e_{r}^{(\delta)} \Big\} \Bigg] \cdot \Bigg[ 
		\overbrace{ \sum\limits_{ \big\{ \vec{m}^{(\gamma)} \big\} }
		m_q^{(\gamma)} }^{\substack{	\text{only term with} \\
						m_q^{(\gamma)} = 1 \\
						\text{remains} }}
		\exp \Big\{ -\beta \sum\limits_{r} m_{r}^{(\gamma)}
		e_{r}^{(\gamma)} \Bigg] }{
			\underbrace{
			\Bigg[ \sum\limits_{\mathscr{M}_{\gamma}} \exp 
			\Big\{ -\beta \sum\limits_{r, \delta \neq \gamma} 
			m_{r}^{(\delta)}e_{r}^{(\delta)} \Big\} \Bigg]
			}_{ \text{first terms cancel} } 
			\cdot \Bigg[ \sum\limits_{ \big\{ \vec{m}^{(\gamma)} 
			\big\} } \exp \Big\{ -\beta
			\underbrace{ \sum\limits_{r} m_{r}^{(\gamma)}
				e_{r}^{(\gamma)} }_{
				\substack{	\text{only one term of this} \\
						\text{sum remains for every} \\
						\text{term of the qrevious }
						\text{sum}} }
				\Big\} \Bigg] } \\\\
	 & = \frac{ \exp \big\{ -\beta\, m_q^{(\gamma)} e_q^{(\gamma)} \big\} }{
	 	\sum\limits_{r} \exp \big\{ -\beta \,
	 	m_{r}^{(\gamma)} e_{r}^{(\gamma)} \big\} }
	\; \underbrace{=}_{\substack{\text{only the } \\ m_r^{(\gamma)} = 1 \\\text{ stays}}} \; \underbrace{\frac{ \exp \big\{ -\beta e_q^{(\gamma)} \big\} }{
		\sum\limits_{r} \exp \big\{ -\beta 
		e_{r}^{(\gamma)} \big\} }}_{\text{soft-max of the mean-fields}}
	\end{array}
\end{equation}
\end{frame}

}

\begin{frame}
\frametitle{Solution for calculating the moments}
$$
		\begin{array}{lll}
	\big< m_q^{(\gamma)} \big>_Q
	& = \frac{ \exp \big\{ -\beta\, m_q^{(\gamma)} e_q^{(\gamma)} \big\} }{
	 	\sum\limits_{r} \exp \big\{ -\beta \,
	 	m_{r}^{(\gamma)} e_{r}^{(\gamma)} \big\} }
	\; = \underbrace{\;\; \frac{ \exp \big\{ -\beta e_q^{(\gamma)} \big\} }{
		\sum\limits_{r} \exp \big\{ -\beta 
		e_{r}^{(\gamma)} \big\} }\;\;}_{\text{soft-max of the mean-fields}}
	\end{array}
$$
\begin{block}{Intuition for above result: ``soft'' clustering}
\begin{itemize}
\itr $\sum_r \langle m_r^{(\gamma)} \rangle = 1$  and $\big< m_q^{(\gamma)} \big>_Q \in [0, 1]$ => assignment probabilities
\itr $\beta \rightarrow \infty: \big< m_q^{(\gamma)} \big>_Q \in \{0, 1\} $ => ``hard assignments'' (cmp.\ K-means)
\end{itemize} 
\end{block}
\end{frame}

\subsubsection{Soft clustering}

\begin{frame}{\subsecname}

\notesonly{
We have so far considered the case of assigning each data point to exactly \textbf{one} cluster. This is enforced by having used a binary definition for 
the assignments variables $m_q^{(\alpha)}$. This ``hard'' assignment is relaxed leading to a so-called ``soft'' or ``fuzzy'' assignment. 
}
Each data point $\vec x^{(\alpha)}$ is assigned to \textbf{all} clusters simultaneously but with different strengths:
The definition of the assignment variable for some point $\alpha$ becomes:
\begin{equation}
\label{eq:assignvarsoft}
\big< m_q^{(\alpha)} \big> \in [0, 1]
\end{equation}
such that
\begin{equation}
\label{eq:assignvarsoftnormalize}
\sum_{q=1}^{M}\big< m_q^{(\alpha)} \big> = 1.
\end{equation}

\notesonly{
The normalization in \eqref{eq:assignvarsoftnormalize} ensures that point $\alpha$ is completely assigned and allows us to interpret the assignment variables as \emph{assignment probabilities. See Fig\ref{fig:clusteringsoft}} for an example. 
The purpose of defining the assignment probabilities as ``expectations'' $\big< \cdot \big>$ will be clarified, when we discuss the soft clustering algorithm.
}
\begin{figure}[h!]
  \centering
\includegraphics[height=4cm]{img/clustering_soft} 
  \caption{Example for soft clustering. Point (9) is assigned to cluster $1$ with a higher probability than to cluster 2: $\big< m_1^{(9)} \big> = 0.51$, $\big< m_2^{(9)} \big> = 0.49$}
  \label{fig:clusteringsoft}
\end{figure}
\end{frame}

\subsubsection{Determining the mean-field parameters}

\notesonly{

Going back to mean-field approximation:

The approximation is achieved by minimizing the KL-divergence between the distribution $P$ and $Q$. 
}

\begin{frame}[t] \slidesonly{\frametitle{Minimization of the KL-divergence}}
\begin{block}{Mean Field equation (c.f. section on Stochastic Optimization for how to arrive at this result)}
\begin{equation}
	\fbox{$ \frac{\partial}{\partial e_l}\big<E_p\big>_Q 
		- \sum\limits_k e_k \frac{\partial}{\partial e_l} \big<s_k\big>_Q = 0
	$}
\end{equation}
\end{block}
\begin{equation}	\frac{\partial \big< E_p \big>_Q}{\partial e_q^{(\alpha)}}
	- \sum\limits_{r, \gamma} \frac{
		\overbrace{ \partial \big< m_r^{(\gamma)} \big>_Q }^{
			\substack{	\text{depends only on} \\
					\text{data point } \gamma }}}{
			\partial e_q^{(\alpha)}}
		e_r^{(\gamma)} \eqexcl 0
\end{equation}
\begin{equation}
	\frac{\partial \big< E_p \big>_Q}{\partial e_q^{(\alpha)}}
	- \sum\limits_r \frac{\partial \big< m_r^{(\alpha)} \big>_Q}{
		\partial e_q^{(\alpha)}}
		e_r^{(\alpha)} \eqexcl 0
\end{equation}

\end{frame}

%--------------------------------------------------------------------------

%--------------------------------------------------------------------------
\begin{frame}[shrink=17] \frametitle{Mean-field annealing for pairwise clustering}
\begin{figure}[!th]
\footnotesize
\removelatexerror
\begin{algorithm}[H]
  \DontPrintSemicolon
  \textbf{Initialization:}\;
  - (max.) number $M$ of partitions, initial  ($\beta_0$) and final  ($\beta_f$) values of the noise parameter, annealing factor  $\eta$,   convergence criterion  $\theta$\;
  - initialize mean-fields  $e_q^{(\alpha)}$ with random numbers $\in [0, 1]$\;

- $\beta \leftarrow \beta_0$\;
\While(annealing){$\beta < \beta_f$}{
\Repeat ( EM $\text{(fixed point iteration)}$){
$\big| \big( e_q^{(\alpha)} \big)_{\mathrm{new}}
	- \big( e_q^{(\alpha)} \big)_{\mathrm{old}} \big| < \theta 
	\hspace{0.3cm}\forall q, \alpha$}{
\hspace{-0.2cm}compute assignment probabilities: 
$ \big< m_q^{(\alpha)} \big>_Q = \frac{ \exp \big\{ -\beta \big(e_q^{(\alpha)}
	\big)_{\mathrm{old}}\big\} }{ \sum\limits_r \exp \big\{ -\beta \big(
	e_r^{(\alpha)} \big)_{\mathrm{old}} \big\} } \hspace{0.3cm}  \forall
	q, \alpha
$\;
\hspace{-0.2cm}compute new mean-fields: 
\hspace{-0.6cm}
$$\hspace{-0.2cm}\big( e_q^{(\alpha)} \big)_{\mathrm{new}} = \frac{2}{p} \frac{1}{
	\sum\limits_{\gamma} \big< m_q^{(\gamma)} \big>_Q } \sum\limits_{\delta}
	\big<m_q^{(\delta)} \big>_Q \cdot \bigg\{ d_{\delta \alpha} - \frac{1}{2} \frac{1}{
		\sum\limits_{\gamma} \big< m_q^{(\gamma)} \big>_Q }
		\sum\limits_{\varepsilon} \big< m_q^{(\varepsilon)}
		\big>_Q d_{\varepsilon \delta} \bigg\} \hspace{0.1cm}\forall q, \alpha$$

}
$\beta \leftarrow \eta \cdot \beta$\;
}
\label{alg:meanFieldClustering}
\caption{Mean-field annealing for pairwise clustering}
\end{algorithm}
\end{figure}
\end{frame}

%--------------------------------------------------------------------------

